{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Synthesizability_2.0.ipynb","provenance":[{"file_id":"1d_o3ClZ4QsnCz8WefkILBa-ir5Ju4SXW","timestamp":1595106720907}],"collapsed_sections":[],"mount_file_id":"1o_5l7kMbc_XGUWbNI5lb5GR9weGPSMrn","authorship_tag":"ABX9TyNEdRSoKLLkjteyy2chUev1"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"1zyAPOigyHKb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602036854496,"user_tz":300,"elapsed":372,"user":{"displayName":"Yunchao Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikgPWhJfvbORI6JXYUle_biVQGEN4yLZCjHbPP=s64","userId":"00292297949549391120"}},"outputId":"dc360b4c-c10f-4b05-cfa3-61ec9f7d67a8"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ksJi2QXPCsIw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1602036854955,"user_tz":300,"elapsed":821,"user":{"displayName":"Yunchao Liu","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GikgPWhJfvbORI6JXYUle_biVQGEN4yLZCjHbPP=s64","userId":"00292297949549391120"}},"outputId":"5a805443-1346-4724-f5a0-7774cc3aa00b"},"source":["# go to correct folder\n","%cd \"/content/drive/My Drive/Academia/lab_projects/Syn_GCN\""],"execution_count":4,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Academia/lab_projects/Syn_GCN\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Zt3TAwlTh9No","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":335},"outputId":"e0fcd4ba-608a-406c-ead0-5f05f31da147"},"source":["# install python packages\n","# install rdkit\n","!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","!chmod +x Miniconda3-latest-Linux-x86_64.sh\n","!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n","!time conda install -q -y -c conda-forge rdkit\n","%matplotlib inline\n","import matplotlib.pyplot as plt\n","import sys\n","import os\n","sys.path.append('/usr/local/lib/python3.7/site-packages/')\n","\n","# install pytorch geometrics\n","%env CUDA=cu101\n","!pip install torch-scatter==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n","!pip install torch-sparse==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n","!pip install torch-cluster==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n","!pip install torch-spline-conv==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.6.0.html\n","!pip install torch-geometric\n","# ! pip install torch-scatter==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n","# ! pip install torch-sparse==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n","# ! pip install torch-cluster==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n","# ! pip install torch-spline-conv==latest+${CUDA} -f https://pytorch-geometric.com/whl/torch-1.5.0.html\n","# ! pip install torch-geometric\n","\n","# install ogb\n","!pip install ogb\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["--2020-10-07 02:15:18--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","Resolving repo.continuum.io (repo.continuum.io)... 104.18.201.79, 104.18.200.79, 2606:4700::6812:c94f, ...\n","Connecting to repo.continuum.io (repo.continuum.io)|104.18.201.79|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh [following]\n","--2020-10-07 02:15:19--  https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n","Resolving repo.anaconda.com (repo.anaconda.com)... 104.16.130.3, 104.16.131.3, 2606:4700::6810:8303, ...\n","Connecting to repo.anaconda.com (repo.anaconda.com)|104.16.130.3|:443... connected.\n","HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n","\n","    The file is already fully retrieved; nothing to do.\n","\n","PREFIX=/usr/local\n","WARNING: md5sum mismatch of tar archive\n","expected: eabd14fa8bcb8e35a2b0a2cbf6b9b7ec\n","     got: 3852968481e00adf4e7a911557b09632  -\n","Unpacking payload ...\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4Ok-gVfJ4N30","colab_type":"code","colab":{}},"source":["# import numpy\n","import numpy as np\n","        \n","# import pandas\n","import pandas as pd\n","\n","# import scipy\n","from scipy import sparse\n","\n","# import rdkit\n","import rdkit\n","from rdkit import Chem\n","from rdkit.Chem import AllChem\n","from rdkit.Chem import rdChemReactions\n","from rdkit.Chem import rdmolfiles\n","from rdkit.Chem.Draw import IPythonConsole\n","\n","# pyG\n","from torch_geometric.data import InMemoryDataset\n","from torch_geometric.utils import convert\n","from torch_geometric.data import Data\n","from torch_geometric.data import DataLoader\n","from torch_geometric.nn import GCNConv\n","from torch_geometric.nn import global_max_pool\n","from torch_geometric.nn import global_mean_pool\n","\n","# import pytorch\n","import torch.nn.functional as F\n","import torch\n","\n","# import print color control\n","from termcolor import colored, cprint\n","\n","# import ogb\n","from ogb.graphproppred import mol_encoder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BDFUwlPobbyG","colab_type":"code","colab":{}},"source":["# function definition\n","# chemical functions\n","def writeSDF(sdf, file_name): # write a sdf to a file\n","    writer=rdkit.Chem.rdmolfiles.SDWriter(file_name)\n","    writer.write(sdf)\n","\n","def SMILES2Adjacency(smiles_str): # SMILES to adjacency matrix\n","    mol = Chem.MolFromSmiles(smiles_str)\n","    if(mol==None):\n","        cprint('SMILES2Adjacency(smiles_str): cannot convert SMILES to mol object', 'red')\n","        return None\n","    else:\n","        return Chem.rdmolops.GetAdjacencyMatrix(mol)\n","\n","def SMILES2Distance(smiles_str): # SMILES to 2D distance matrix\n","    mol= Chem.MolFromSmiles(smiles_str)\n","    return Chem.rdmolops.GetDistanceMatrix(mol,-1)   \n","\n","def SMILES2Distance3D(smiles_str, n=0): # SMILES to 3D distance matrix; n is the number of conformer\n","    dist=[]\n","    if n == 0:\n","        sdf = SMILES2SDF(smiles_str)\n","        dist.append(Chem.rdmolops.Get3DDistanceMatrix(sdf, -1))\n","    else:\n","        sdfs, ids = SMILES2SDFConformers(smiles_str, n)\n","        for id in ids:\n","            dist.append(Chem.rdmolops.Get3DDistanceMatrix(sdfs, ids[id]))\n","    return dist\n","\n","\n","def SMILES2SDF(smiles_str): # SMILES to a single structure without multiple conformers\n","    mol = Chem.MolFromSmiles(smiles_str)\n","    mol_H = Chem.AddHs(mol)\n","    AllChem.EmbedMolecule(mol_H, AllChem.ETKDG())\n","    AllChem.UFFOptimizeMolecule(mol_H,1000)\n","    sdf = Chem.rdmolops.RemoveAllHs(mol_H)\n","    return sdf\n","\n","def SMILES2SDFConformers(smiles_str, n): # SMILES to SDF structure with multiple conformers; n is the number of conformers. Recommendation: n=50 for rotation bonds(RB) <=7; n=200 if 8<=RB<=12; n=300 if RB>=13\n","    mol = Chem.MolFromSmiles(smiles_str)\n","    mol = Chem.AddHs(mol)\n","\n","    ids=AllChem.EmbedMultipleConfs(mol, numConfs=n, params=AllChem.ETKDG())\n","    sdfs = Chem.rdmolops.RemoveAllHs(mol)\n","    return sdfs, list(ids)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HBt0xX99KosB","colab_type":"code","colab":{}},"source":["# data preprocess\n","%cd /content/drive/My Drive/Academia/lab_projects/Syn_GCN/ \n","\n","# parameters\n","num_subsample=10000 # num of subsample\n","byproduct_cutoff=10 # if the smiles string length is less than this number, it will be classified as byproduct; otherwise as main products\n","data_type = torch.float\n","training_perc = 0.8 # percentage of training data in the dataset\n","val_perc = 0.1 # percentage of validation data in the dataset\n","test_perc = 1-training_perc - val_perc # percentage of testing data in the dataset\n","\n","# load data\n","df = pd.read_csv('dataSetB.csv', usecols=['rxnSmiles_Mapping_NameRxn'])\n","\n","# ramdom subsampling\n","# sampled_rxn = np.random.choice(df.rxnSmiles_Mapping_NameRxn, num_subsample, replace = False)\n","# df = df.loc[df.rxnSmiles_Mapping_NameRxn.isin(sampled_rxn)]\n","\n","# fixed sampling for debugging. Only first num_subsample will be used\n","df = df.head(num_subsample)\n","\n","class SynDataset(InMemoryDataset):\n","  def __init__(self, root, transform=None, pre_transform=None):\n","    super(SynDataset, self).__init__(root, transform, pre_transform)\n","    self.data, self.slices = torch.load(self.processed_paths[0])\n","\n","  @property\n","  def raw_file_names(self):\n","    return ['dataSetB']\n","  @property\n","  def processed_file_names(self):\n","    return ['processed_data.dataset']\n","\n","  def download(self):\n","    pass\n","  \n","  def process(self):\n","    mul_products_rxn_list=[] # a list containing all reactions with more than one products\n","    num_valid_products = 0 # number of main products\n","    num_none_mol = 0 # number for SMILES that cannot be convert to adjacency matrix\n","      \n","    curated_training = []\n","\n","    for i in range(num_subsample):\n","      rxn = rdChemReactions.ReactionFromSmarts(df.rxnSmiles_Mapping_NameRxn[i])\n","      products=rxn.GetProducts()\n","    #   if i==0:\n","    #     print('reaction '+str(i) +' has ' + str(len(products)) + ' products')\n","      if(len(products)>1):\n","        mul_products_rxn =(i, len(products))\n","        print('mul_product-(rxn_id' + ', num_products):'+ str(mul_products_rxn))\n","        mul_products_rxn_list.append(mul_products_rxn)\n","\n","      for j in range(len(products)):\n","        product_smile = rdmolfiles.MolToSmiles(products[j])\n","        if len(product_smile)<byproduct_cutoff:\n","          cprint('byproduct filtered out:'+'str(len(product_smile)):'+ product_smile,'green')\n","          continue\n","        else:\n","          # first_curated.append(product_smile) # add main product to curated training data\n","          num_valid_products+=1\n","        #   if i == 0: # print full reaction\n","        #     cprint(str(len(product_smile))+':'+ product_smile,'blue')\n","          if SMILES2Adjacency(product_smile) is not None:\n","            A = SMILES2Adjacency(product_smile) # get adjacency matrix of the product, in numpy.matrix \n","            num_nodes = len(A) # get the num of nodes\n","            sA = sparse.csr_matrix(A) # convert A from numpy.matrix to scipy sparse matrix\n","            edge_index, edge_weight=convert.from_scipy_sparse_matrix(sA) # convert from scipy sparse matrix to edge_index\n","            x = torch.tensor([[1]*num_nodes]).t()\n","            y = 1\n","            data = Data(x=x, edge_index=edge_index, y=y, dtype=torch.long)\n","            if i<10 :\n","                print(\"i:\", i)\n","                print('data:'+str(data))\n","            # print(edge_index)\n","            curated_training.append(data)\n","          else:\n","            num_none_mol+=1\n","            continue\n","    \n","    data, slices = self.collate(curated_training)\n","    torch.save((data, slices), self.processed_paths[0])\n","    print(\"num_none_mol:\",num_none_mol)\n","\n","dataset = SynDataset('data')\n","\n","\n","dataset = dataset.shuffle()\n","dataset_size = len(dataset)\n","print('total num of data:', dataset_size)\n","num_training = int(dataset_size*training_perc)\n","num_val = int(dataset_size*val_perc)\n","train_dataset = dataset[:num_training]\n","val_dataset = dataset[num_training:(num_training + num_val)]\n","test_dataset = dataset[(num_training + num_val):]\n","print('num_training, num_val, num_test:',num_training, num_val, len(test_dataset))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mJgMhlKDtI56","colab_type":"code","colab":{}},"source":["class AtomEncoder(torch.nn.Module):\n","    def __init__(self, hidden_channels):\n","        super(AtomEncoder, self).__init__()\n","\n","        self.embeddings = torch.nn.ModuleList()\n","\n","        for i in range(9):\n","            self.embeddings.append(torch.nn.Embedding(100, hidden_channels))\n","\n","    def reset_parameters(self):\n","        for embedding in self.embeddings:\n","            embedding.reset_parameters()\n","\n","    def forward(self, x):\n","        if x.dim() == 1:\n","            x = x.unsqueeze(1)\n","\n","        out = 0\n","        for i in range(x.size(1)):\n","            out += self.embeddings[i](x[:, i])\n","        return out\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jzeX5moMBcK8","colab_type":"code","colab":{}},"source":["# main codes\n","\n","num_node_features = 1\n","num_classes = 2\n","batch_size =2\n","num_epochs = 2\n","\n","class Net(torch.nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.emb = AtomEncoder(num_node_features)\n","        self.conv1 = GCNConv(num_node_features, 16)\n","        self.conv2 = GCNConv(16, 2)\n","      \n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        # print('data:',data)\n","        x = self.emb(x)\n","        x = self.conv1(x, edge_index)\n","        # print('here')\n","        x = F.relu(x)\n","        x = F.dropout(x, training=self.training)\n","        x = self.conv2(x, edge_index)\n","        # return F.log_softmax(x, dim=1)\n","        return global_mean_pool(F.log_softmax(x, dim=1), batch = data.batch)\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","model = Net().to(device)\n","print(f\"devide:{device}\")\n","#test_dataset = TestData(root='/tmp/Cora', name='Cora')\n","#train_dataset= train_dataset\n","\n","# data = dataset[1].to(device)\n","\n","data = train_dataset[1].to(device)\n","# print(\"data:\",data)\n","# data = test_dataset.to(device)\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.005)\n","\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","def train():\n","    model.train()\n","    for data in train_loader:\n","        data.to(device)\n","        optimizer.zero_grad()\n","        out = model(data)\n","        # print(f\"out:{out}, y:{data.y}\")\n","        loss = F.nll_loss(out, data.y)\n","        loss.backward()\n","        optimizer.step()\n","\n","def test(loader):\n","    model.eval()\n","    correct = 0\n","    for data in loader:\n","        data.to(device)\n","        out = model(data)\n","        # print(out)\n","        pred = out.argmax(dim=1)\n","        correct += int((pred==data.y).sum())\n","    return correct/len(loader.dataset)\n","\n","\n","\n","for epoch in range(num_epochs):\n","    train()\n","    train_acc = test(train_loader)\n","    test_acc = test(test_loader)\n","    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}')\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Eb1o51UFISft","colab_type":"code","colab":{}},"source":["# Test Zone\n","loader = DataLoader(dataset, batch_size=3)\n","for batch in loader:\n","    print(batch)\n","    print(batch.batch)\n","\n","def createData(smiles):\n","    A = SMILES2Adjacency(smiles) # get adjacency matrix of the product, in numpy.matrix \n","    # print(A)\n","    num_nodes = len(A) # get the num of nodes\n","    sA = sparse.csr_matrix(A) # convert A from numpy.matrix to scipy sparse matrix\n","    edge_index, edge_weight=convert.from_scipy_sparse_matrix(sA) # convert from scipy sparse matrix to edge_index\n","    x = torch.tensor([[1]*num_nodes]).t()\n","    y = 1\n","    data = Data(x=x, edge_index=edge_index, y=y)\n","    return data\n","\n","# a ='[NH2:11][CH2:12][CH2:13][CH2:14][CH2:15][C@H:16]([NH:21][C:22](=[O:37])[NH:23][c:24]1[cH:29][c:28]([O:30][CH3:31])[cH:27][c:26]([C:32]([CH3:33])([CH3:34])[CH3:35])[c:25]1[OH:36])[C:17]([O:19][CH3:20])=[O:18]'\n","b ='[C:1](=[O:2])([c:3]1[cH:4][c:5]([N+:6](=[O:7])[O-:8])[c:9]([S:10][c:11]2[c:12]([Cl:13])[cH:14][n:15][cH:16][c:17]2[Cl:18])[s:19]1)[NH:20][c:21]1[cH:22][cH:23][cH:24][c:25]2[cH:26][n:27][cH:28][cH:29][c:30]12'\n","c ='[CH2:1]([c:2]1[cH:3][cH:4][c:5](-[c:6]2[n:7][c:8]([CH3:9])[c:10]([CH2:11][O:12][c:13]3[cH:14][cH:15][c:16]([C@H:17]([CH2:18][C:19](=[O:20])[N:21]4[C:22](=[O:23])[O:24][CH2:25][C@@H:26]4[CH2:27][c:28]4[cH:29][cH:30][cH:31][cH:32][cH:33]4)[c:34]4[cH:35][cH:36][o:37][n:38]4)[cH:39][cH:40]3)[s:41]2)[cH:42][cH:43]1)[N:46]([CH2:45][CH3:44])[CH2:47][CH3:48]'\n","print(Chem.MolFromSmiles(a).GetNumAtoms())\n","print(Chem.MolFromSmiles(b).GetNumAtoms())\n","print(Chem.MolFromSmiles(c).GetNumAtoms())\n","print(createData(a))\n","print(createData(b))\n","print(createData(c))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TaDHMR66IVYj","colab_type":"code","colab":{}},"source":["#==========================\n","# Testing Zone\n","\n","# smiles= '[CH3:1][N:10]1[CH2:9][c:7]2[c:6](-[cH:5][cH:4][c:3]([Cl:2])[cH:8]2)-[n:17]2[c:12]([CH2:11]1)-[n:13][n:14][c:15]2'\n","# #smiles= 'CC(=O)OC1=CC=CC=C1C(=O)O'\n","# n=10\n","\n","\n","\n","# k= SMILES2Distance3D(smiles,n)\n","# for i in range(len(k)):\n","#   print(k[i][3])\n","#   print('\\n')\n","# print(len(k))\n","\n","\n","# sdfs, ids = SMILES2SDFConformers(smiles, n)\n","# sdfs_list =[]\n","# for i in range(len(ids)):\n","#   file = 'test_confs'+str(i)+'.sdf'\n","#   sdfs_list.append(Chem.rdmolfiles.MolToMolFile(sdfs , file, True, ids[i]))\n","# # Chem.rdmolops.Get3DDistanceMatrix(sdfs,ids[1])\n","# # for i in range(len(sdfs_list)):\n","# #   print(sdfs_list[3])\n","\n","# %cd test\n","# # writeSDF(sdfs, 'test_confs.sdf')\n","# writeSDF(SMILES2SDF(smiles),'test_no_conf.sdf')\n","# writeSDF(Chem.MolFromSmiles(smiles),'test_2D.sdf')\n","# %cd .."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SxnzcD4GjlOX","colab_type":"code","colab":{}},"source":["# test\n","import torch\n","from torch_geometric.nn import MessagePassing\n","from torch_geometric.utils import add_self_loops, degree\n","\n","class GCNConv(MessagePassing):\n","    def __init__(self, in_channels, out_channels):\n","        super(GCNConv, self).__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n","        self.lin = torch.nn.Linear(in_channels, out_channels)\n","\n","    def forward(self, x, edge_index):\n","        # x has shape [N, in_channels]\n","        # edge_index has shape [2, E]\n","\n","        # Step 1: Add self-loops to the adjacency matrix.\n","        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n","\n","        # Step 2: Linearly transform node feature matrix.\n","        x = self.lin(x)\n","\n","        # Step 3: Compute normalization.\n","        row, col = edge_index\n","        deg = degree(col, x.size(0), dtype=x.dtype)\n","        deg_inv_sqrt = deg.pow(-0.5)\n","        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n","\n","        # Step 4-5: Start propagating messages.\n","        return self.propagate(edge_index, x=x, norm=norm)\n","\n","    def message(self, x_j, norm):\n","        # x_j has shape [E, out_channels]\n","\n","        # Step 4: Normalize node features.\n","        return norm.view(-1, 1) * x_j\n","\n","edge_index = torch.tensor([[0, 1, 1, 2],\n","                           [1, 0, 2, 1]], dtype=torch.long)\n","x = torch.tensor([[-1], [0], [1]], dtype=torch.float)\n","\n","conv = GCNConv(1, 10)\n","conv.train\n","x = conv(x, edge_index)\n","print(x)\n","\n","# row, col = edge_index\n","# deg = degree(col, x.size(0), dtype=x.dtype)\n","# deg_inv_sqrt = deg.pow(-0.5)\n","# norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n","\n","# a= torch.tensor([[1,2],[3,4],[5,6],[8,8]])\n","# print(a.view(-1,3))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWI43dK2jros","colab_type":"code","colab":{}},"source":["# test\n","a = torch.ones(5)\n","print(a)\n","b = a.numpy()\n","print(b)\n","a.add_(1)\n","print(a)\n","print(b)"],"execution_count":null,"outputs":[]}]}